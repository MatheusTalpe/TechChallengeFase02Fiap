{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento da base\n",
    "\n",
    "Nesta seção, iremos realizar o carregamento e validação básica da base.\n",
    "\n",
    "Fonte dos dados: https://www.kaggle.com/datasets/mirichoi0218/insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas: 1338\n"
     ]
    }
   ],
   "source": [
    "# Print da quantidade de linhas:\n",
    "\n",
    "row_count = len(df)\n",
    "print(\"Linhas:\", row_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação de inconsistências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica inconsistências\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "Na seção abaixo, iremos realizar o mesmo pré processamento descrito na entrega do tech challenge da fase 1. Onde a base será normalizada e terá seus outliers removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separa o dataframe original em dados categoricos e numericos\n",
    "df_categoricos = df.select_dtypes(include=['object', 'category'])\n",
    "df_numericos = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Inicializa OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Aplica o fit transform nos dados categoricos\n",
    "one_hot_encoded = encoder.fit_transform(df_categoricos)\n",
    "\n",
    "# Cria um DataFrame com os dados categoricos que tiveram o one hot encoding aplicado\n",
    "encoded_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatena o DataFrame de dados numericos com o DataFrame que contém o resultado do one hot encoding\n",
    "df_result_one_hot_encoding = pd.concat([encoded_df, df_numericos], axis=1)\n",
    "\n",
    "# Exibe as primeiras linhas para verificarmos o resultado\n",
    "#print(df_result_one_hot_encoding.head(5))\n",
    "\n",
    "# Exibe a quantidade de nulos gerados para validar se não foi criado um DataFrame com inconsistências\n",
    "#print(\"Quantidade de nulos:\\n\", df_result_one_hot_encoding.isnull().sum())\n",
    "\n",
    "# Printa a quantidade de linhas antes da remoção de outliers\n",
    "row_count = len(df_result_one_hot_encoding)\n",
    "#print(\"Row count:\", row_count)\n",
    "\n",
    "# Separa e printa as 5 ocorrências de maior valor para o IMC\n",
    "top_bmi = df_result_one_hot_encoding.nlargest(5, 'bmi')\n",
    "#print(top_bmi['bmi'])\n",
    "\n",
    "# Calcula os percentis de Q1 e Q3 que serão utilizados no cálculo e a dispersão (IQR)\n",
    "Q1 = df_result_one_hot_encoding['bmi'].quantile(0.25)\n",
    "Q3 = df_result_one_hot_encoding['bmi'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define os limites de outlier\n",
    "# Utilizaremos as formulas padrão de outliers, o resultado define quais valores serão os limites máximos para um valor ser considerado outlier ou não.\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove os outliers\n",
    "df_no_outliers = df_result_one_hot_encoding[(df_result_one_hot_encoding['bmi'] <= upper_bound)]\n",
    "\n",
    "# Separa e printa as 5 ocorrências de maior valor para o IMC\n",
    "top_bmi = df_result_one_hot_encoding.nlargest(5, 'bmi')\n",
    "#print(top_bmi['bmi'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza o fit transform, normalizando as colunas\n",
    "dados_normalizados = scaler.fit_transform(df_no_outliers)\n",
    "\n",
    "# Converte o resultado do fit transform novamente em um data frame\n",
    "df_normalizado = pd.DataFrame(dados_normalizados, columns=df_no_outliers.columns)\n",
    "\n",
    "# Printa as informações normalizadas\n",
    "#print(df_normalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução Random Forest sem algoritmo genético\n",
    "\n",
    "Nesta seção, iremos realizar a execução do algoritmo de random forest da maneira padrão, sem selecionarmos os hiperparametros. Afim de coletarmos a pontuação R2 para posteriormente compararmos com performance do algoritmo genético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontuacao R2 sem algoritmo genetico:  0.8304680675627977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = df_normalizado[['smoker_yes', 'smoker_no', 'age', 'children', 'bmi']]  \n",
    "y = df_normalizado['charges'] \n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Separa os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "score = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Pontuacao R2 sem algoritmo genetico: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar acima, a pontuação R2 obtida da execução do algoritmo de Random Forest foi de: 0.8304680675627977\n",
    "\n",
    "\n",
    "=================================================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução do algoritmo Genetico\n",
    "\n",
    "Na seção abaixo, iremos executar uma função com um algoritmo genético criado para otimizar os hiperparâmetros do algoritmo de random forest e coletarmos seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def random_forest_genetic_algorithm(X, Y, generations=3, population_size=30, elitism=2, percent_childs=0.3):\n",
    "    \n",
    "    # Initializa população com individuos gerados com genes aleatorios\n",
    "    def init_population():\n",
    "        return [{\n",
    "            'n_estimators': np.random.randint(10, 200),\n",
    "            'max_depth': np.random.choice([None, np.random.randint(1, 100)]),\n",
    "            'min_samples_split': np.random.randint(2, 30),\n",
    "            'min_samples_leaf': np.random.randint(1, 30),\n",
    "            'max_features': np.random.choice(['sqrt', 'log2'])\n",
    "        } for _ in range(population_size)]\n",
    "\n",
    "    # Avalia a aptidação dos individuos de uma população e a retorna uma lista rankeada em ordem decrescente\n",
    "    def evaluate_population(population, X_train, X_test, y_train, y_test):\n",
    "        scores = []\n",
    "        for individual in population:\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=individual['n_estimators'],\n",
    "                max_depth=individual['max_depth'],\n",
    "                min_samples_split=individual['min_samples_split'],\n",
    "                min_samples_leaf=individual['min_samples_leaf'],\n",
    "                max_features=individual['max_features'],\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            score = r2_score(y_test, predictions)\n",
    "            scores.append((score, individual))\n",
    "\n",
    "        return sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Gera um filho a partir de dois pais, utilizando Crossover Uniforme\n",
    "    def crossover(parent1, parent2):\n",
    "        child = {}\n",
    "        for key in parent1:\n",
    "            if np.random.rand() > 0.5:\n",
    "                child[key] = parent1[key]\n",
    "            else:\n",
    "                child[key] = parent2[key]\n",
    "        return child\n",
    "    \n",
    "    # Aplica mutação \n",
    "    def mutate(individual, mutation_rate=0.3):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            # Randomly change one of the hyperparameters\n",
    "            mutation = np.random.choice(list(individual.keys()))\n",
    "            if mutation in ['n_estimators', 'min_samples_split', 'min_samples_leaf']:\n",
    "              individual[mutation] = np.random.randint(10, 200) if mutation == 'n_estimators' else np.random.randint(2, 30) \n",
    "            elif mutation == 'max_depth':\n",
    "                individual['max_depth'] = np.random.choice([None, np.random.randint(1, 100)])\n",
    "            elif mutation == 'max_features':\n",
    "                individual['max_features'] = np.random.choice(['sqrt', 'log2'])\n",
    "        return individual\n",
    "\n",
    "    \n",
    "    # Divide os dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializa a primeira geração\n",
    "    population = init_population()\n",
    "\n",
    "    # Itera e gera cada geração até que o numero maximo de gerações seja atingido\n",
    "    for n in range(generations):\n",
    "        ranked_population = evaluate_population(population, X_train, X_test, y_train, y_test)\n",
    "        #print(\"Populacao rankeada: \", ranked_population)\n",
    "\n",
    "        # Seleciona os melhores individuos de acordo com o elitismo parametrizado\n",
    "        top_scores = [ind[0] for ind in ranked_population[:elitism]]\n",
    "        top_individuals = [ind[1] for ind in ranked_population[:elitism]]\n",
    "        print(f\"Melhores scores da geracao {n}: \", top_scores)\n",
    "        #print(f\"Melhores individuos da geracao {n}: \", top_individuals)\n",
    "\n",
    "        # Gera uma nova população aleatoria\n",
    "        new_population = init_population()\n",
    "\n",
    "        #print(\"populacao inicial: \", new_population)\n",
    "        # Substitui % da populacao com individuos gerados a partir do crossover dos melhores selecionados a partir da população anterior\n",
    "        i = 0\n",
    "        while i <= population_size * percent_childs - 1:\n",
    "            parent1, parent2 = np.random.choice(top_individuals, 2, replace=False)\n",
    "            #print (\"parent 1: \", parent1)\n",
    "            #print (\"parent 2: \", parent2)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child)\n",
    "            #print (\"child: \", child)\n",
    "            #print (\"\\n\")\n",
    "            new_population[i] = child\n",
    "            i += 1\n",
    "            \n",
    "        #print(\"populacao mista: \", new_population)\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "\n",
    "    # Avalia a população final e recebe a lista rankeada\n",
    "    final_ranking = evaluate_population(population, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Seleciona as informações do melhor individuo\n",
    "    best_score, best_hyperparameters = final_ranking[0]\n",
    "\n",
    "    # Printa o score final e hiperaparametros utilizados\n",
    "    print(\"\\n\")\n",
    "    print(f\"Score R2 do melhor individuo da geração final: {best_score}\")\n",
    "    print(f\"Hiperparametros do melhor individuo da geração final : {best_hyperparameters}\")\n",
    "\n",
    "    return best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores scores da geracao 0:  [0.8675690460193384, 0.8661600446374275, 0.8654235137621262, 0.8653370610295994]\n",
      "Melhores scores da geracao 1:  [0.8675690460193384, 0.8675690460193384, 0.8675690460193384, 0.8675690460193384]\n",
      "Melhores scores da geracao 2:  [0.8677527740435681, 0.8675690460193384, 0.8675690460193384, 0.8675690460193384]\n",
      "Melhores scores da geracao 3:  [0.8695267420820865, 0.8677527740435681, 0.8675690460193384, 0.8675690460193384]\n",
      "Melhores scores da geracao 4:  [0.8695267420820865, 0.8677527740435681, 0.8677527740435681, 0.8675690460193384]\n",
      "Melhores scores da geracao 5:  [0.8695617793541377, 0.8695617793541377, 0.8677527740435681, 0.8677527740435681]\n",
      "Melhores scores da geracao 6:  [0.8695617793541377, 0.8695617793541377, 0.8695617793541377, 0.8695617793541377]\n",
      "Melhores scores da geracao 7:  [0.8708333955292237, 0.8695617793541377, 0.8695617793541377, 0.8695617793541377]\n",
      "Melhores scores da geracao 8:  [0.8708333955292237, 0.8708333955292237, 0.8697980291709999, 0.8695617793541377]\n",
      "Melhores scores da geracao 9:  [0.8708333955292237, 0.8708333955292237, 0.8708333955292237, 0.8708333955292237]\n",
      "\n",
      "\n",
      "Score R2 do melhor individuo da geração final: 0.8709291185435767\n",
      "Hiperparametros do melhor individuo da geração final : {'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': np.str_('log2')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 52,\n",
       " 'max_depth': 5,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': np.str_('log2')}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_genetic_algorithm(X, y, generations=10, population_size=30, elitism=4, percent_childs=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
